{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c989cb2e-0a50-403f-8b58-af61e44a79f3",
   "metadata": {},
   "source": [
    "# Simple prefix sum parallel (CUDA) GPU\n",
    "\n",
    "Using the Blelloch algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195212d8",
   "metadata": {},
   "source": [
    "## Single block simplified version\n",
    "\n",
    "Some GPU + Windows + current CUDA.jl versions have a known bug with dynamic shared memory allocation.\n",
    "So using static shared memory for running this computation under Windows 10.\n",
    "\n",
    "This kernel only supports **power-of-two** n, for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b708af85-d04f-4ab7-9b8e-b294cc626978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpu_scan_static! (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CUDA\n",
    "\n",
    "function kernel_blelloch_scan_static!(data, n)\n",
    "    T = eltype(data)\n",
    "    sdata = @cuStaticSharedMem(T, 1024)\n",
    "\n",
    "    tid = threadIdx().x\n",
    "    t = tid - 1  # 0-based\n",
    "\n",
    "    if tid <= n\n",
    "        sdata[tid] = data[tid]\n",
    "    else\n",
    "        return\n",
    "    end\n",
    "    sync_threads()\n",
    "\n",
    "    # upsweep\n",
    "    offset = 1\n",
    "    while offset < n\n",
    "        paircount = n ÷ (2 * offset)\n",
    "        if t < paircount\n",
    "            ai = offset*(2t+1)\n",
    "            bi = offset*(2t+2)\n",
    "            sdata[bi] += sdata[ai]\n",
    "        end\n",
    "        offset *= 2\n",
    "        sync_threads()\n",
    "    end\n",
    "\n",
    "    if tid == 1\n",
    "        sdata[n] = zero(T)\n",
    "    end\n",
    "    sync_threads()\n",
    "\n",
    "    # downsweep\n",
    "    offset = n ÷ 2\n",
    "    while offset ≥ 1\n",
    "        paircount = n ÷ (2 * offset)\n",
    "        if t < paircount\n",
    "            ai = offset*(2t+1)\n",
    "            bi = offset*(2t+2)\n",
    "            tmp = sdata[ai]\n",
    "            sdata[ai] = sdata[bi]\n",
    "            sdata[bi] += tmp\n",
    "        end\n",
    "        offset ÷= 2\n",
    "        sync_threads()\n",
    "    end\n",
    "\n",
    "    data[tid] = sdata[tid]\n",
    "    return\n",
    "end\n",
    "\n",
    "function gpu_scan_static!(x::CuArray)\n",
    "    n = length(x)\n",
    "    @assert ispow2(n)\n",
    "    threads = n\n",
    "    @cuda threads=threads kernel_blelloch_scan_static!(x, n)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b83d72-fbe0-4636-8476-700de4814ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float32}:\n",
       " 0.0\n",
       " 0.5748641\n",
       " 1.2661473\n",
       " 2.2272089\n",
       " 3.1423702\n",
       " 3.785553\n",
       " 4.3061175\n",
       " 4.3568935\n",
       " 4.7280483\n",
       " 5.645898"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1024\n",
    "x = CuArray(rand(Float32, N))\n",
    "gpu_scan_static!(x)\n",
    "collect(x)[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bcc951-d92b-48e2-a111-3af430e9b8e0",
   "metadata": {},
   "source": [
    "CPU serial version for checking and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a27ac5-e5e9-456d-8407-4e517661d680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cpu_serial_scan (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "# CPU reference exclusive scan (Blelloch-compatible)\n",
    "function cpu_serial_scan(x::Vector{T}) where T\n",
    "    n = length(x)\n",
    "    out = Vector{T}(undef, n)\n",
    "    out[1] = zero(T)\n",
    "    for i in 2:n\n",
    "        out[i] = out[i - 1] + x[i - 1]\n",
    "    end\n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4f9697-8dfe-47ee-96e8-6c0c32ffd671",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84ad045-bc3f-4e68-9a05-209b5fdcd219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 CPU: Float32[0.0, 0.31806326, 0.9628847, 1.1387913, 1.6424044, 2.3615456, 2.6505861, 2.9473846, 3.331805, 3.7266717]\n",
      "First 10 GPU: Float32[0.0, 0.31806326, 0.9628847, 1.1387913, 1.6424046, 2.3615458, 2.6505864, 2.9473848, 3.3318052, 3.726672]\n",
      "Correct? true\n",
      "\n",
      "=== Timing ===\n",
      "CPU:\n",
      "  643.114 ns (3 allocations: 4.09 KiB)\n",
      "GPU:\n",
      "  26.800 μs (7 allocations: 144 bytes)\n"
     ]
    }
   ],
   "source": [
    "N = 1024           # must be power of 2, and max is 1024 bcz this is single block version\n",
    "h_input = rand(Float32, N)\n",
    "\n",
    "# CPU serial scan\n",
    "cpu_ref = cpu_serial_scan(h_input)\n",
    "\n",
    "# GPU scan\n",
    "d_input = CuArray(h_input)\n",
    "gpu_scan_static!(d_input)\n",
    "gpu_result = collect(d_input)\n",
    "\n",
    "println(\"First 10 CPU: \", cpu_ref[1:10])\n",
    "println(\"First 10 GPU: \", gpu_result[1:10])\n",
    "println(\"Correct? \", cpu_ref ≈ gpu_result)\n",
    "\n",
    "println(\"\\n=== Timing ===\")\n",
    "\n",
    "println(\"CPU:\")\n",
    "@btime cpu_serial_scan($h_input);\n",
    "println(\"GPU:\")\n",
    "@btime begin\n",
    "    copyto!(d_input, h_input)   # reset input on GPU\n",
    "    gpu_scan_static!(d_input)\n",
    "    synchronize()\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dcdaa1-1af3-41a8-9ae8-c4efef272d5d",
   "metadata": {},
   "source": [
    "## Multi block simplified version\n",
    "\n",
    "Utilizes the single block version above, so this is also exclusive scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4b36ffe-6f25-42f9-9b51-31293b7ce803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpu_scan_multiblock! (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CUDA\n",
    "\n",
    "# -------------------------\n",
    "# 1. Phase 1 kernel: scan each block\n",
    "# -------------------------\n",
    "function kernel_phase1!(data, block_sums, n)\n",
    "    T = eltype(data)\n",
    "    sdata = @cuStaticSharedMem(T, 1024)\n",
    "\n",
    "    tid = threadIdx().x\n",
    "    t   = tid - 1\n",
    "\n",
    "    block_size = 1024\n",
    "    block = blockIdx().x\n",
    "\n",
    "    gid = (block - 1) * block_size + tid\n",
    "\n",
    "    # load\n",
    "    if gid <= n\n",
    "        sdata[tid] = data[gid]\n",
    "    else\n",
    "        sdata[tid] = zero(T)\n",
    "    end\n",
    "    sync_threads()\n",
    "\n",
    "    # upsweep\n",
    "    offset = 1\n",
    "    while offset < block_size\n",
    "        paircount = block_size ÷ (2 * offset)\n",
    "        if t < paircount\n",
    "            ai = offset * (2t + 1)\n",
    "            bi = offset * (2t + 2)\n",
    "            sdata[bi] += sdata[ai]\n",
    "        end\n",
    "        offset *= 2\n",
    "        sync_threads()\n",
    "    end\n",
    "\n",
    "    # write block sum\n",
    "    if tid == 1\n",
    "        block_sums[block] = sdata[block_size]\n",
    "        sdata[block_size] = zero(T)\n",
    "    end\n",
    "    sync_threads()\n",
    "\n",
    "    # downsweep\n",
    "    offset = block_size ÷ 2\n",
    "    while offset ≥ 1\n",
    "        paircount = block_size ÷ (2 * offset)\n",
    "        if t < paircount\n",
    "            ai = offset * (2t + 1)\n",
    "            bi = offset * (2t + 2)\n",
    "            tmp = sdata[ai]\n",
    "            sdata[ai] = sdata[bi]\n",
    "            sdata[bi] += tmp\n",
    "        end\n",
    "        offset ÷= 2\n",
    "        sync_threads()\n",
    "    end\n",
    "\n",
    "    # write back\n",
    "    if gid <= n\n",
    "        data[gid] = sdata[tid]\n",
    "    end\n",
    "\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "# -------------------------\n",
    "# 2. Phase 3 kernel: add scanned block sums to each block\n",
    "# -------------------------\n",
    "function kernel_add_offsets!(data, block_offsets, n)\n",
    "    block_size = 1024\n",
    "    block = blockIdx().x\n",
    "    tid   = threadIdx().x\n",
    "\n",
    "    gid = (block - 1) * block_size + tid\n",
    "\n",
    "    if block > 1 && gid <= n\n",
    "        data[gid] += block_offsets[block]\n",
    "    end\n",
    "\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "# -------------------------\n",
    "# 3. Multi-block scan wrapper\n",
    "# -------------------------\n",
    "function gpu_scan_multiblock!(x::CuArray)\n",
    "    N = length(x)\n",
    "    block_size = 1024\n",
    "    n_blocks = cld(N, block_size)\n",
    "\n",
    "    d_block_sums = CuArray(zeros(eltype(x), n_blocks))\n",
    "\n",
    "    # phase 1\n",
    "    @cuda threads=block_size blocks=n_blocks kernel_phase1!(x, d_block_sums, N)\n",
    "    synchronize()\n",
    "\n",
    "    # phase 2: scan block sums (reuse the above single-block scan)\n",
    "    if n_blocks > 1\n",
    "        gpu_scan_static!(d_block_sums)\n",
    "        synchronize()\n",
    "    end\n",
    "\n",
    "    # phase 3\n",
    "    if n_blocks > 1\n",
    "        @cuda threads=block_size blocks=n_blocks kernel_add_offsets!(x, d_block_sums, N)\n",
    "        synchronize()\n",
    "    end\n",
    "\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2f0bf-163d-41cf-9f50-e362f9c167db",
   "metadata": {},
   "source": [
    "### Benchmarking using a large enough problem\n",
    "\n",
    "Now we can benchmark this paricular GPU version to the serial CPU version.\n",
    "But don't expect this GPU version to be faster than the CPU version, as it is not using warp optimization (more synchronization overheads), has kernel launching overhead, and suffer from GPU ALU under-utilization (memory bandwidth, prefix sum is memory-bound). Also CPU version has L2/L3 cache benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae5493d-643e-43fc-a030-c9f84da1d68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctness check:\n",
      "true\n",
      "\n",
      "=== Benchmark ===\n",
      "CPU serial exclusive scan:\n",
      "  39.100 μs (3 allocations: 256.07 KiB)\n",
      "\n",
      "GPU multi-block exclusive scan:\n",
      "  127.400 μs (166 allocations: 3.02 KiB)\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "# Problem size (large-ish)\n",
    "N = 2^16\n",
    "h = rand(Float32, N)\n",
    "d = CuArray(h)\n",
    "\n",
    "# Warm-up (important: triggers compilation)\n",
    "gpu_scan_multiblock!(d)\n",
    "synchronize()\n",
    "\n",
    "println(\"Correctness check:\")\n",
    "cpu = cpu_serial_scan(h)\n",
    "gpu = collect(d)\n",
    "println(cpu ≈ gpu)\n",
    "\n",
    "println(\"\\n=== Benchmark ===\")\n",
    "\n",
    "println(\"CPU serial exclusive scan:\")\n",
    "@btime cpu_serial_scan($h);\n",
    "\n",
    "println(\"\\nGPU multi-block exclusive scan:\")\n",
    "@btime begin\n",
    "    copyto!($d, $h)           # reset GPU input\n",
    "    gpu_scan_multiblock!($d)\n",
    "    synchronize()             # wait for GPU completion\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d4d21-9231-48b0-800f-07d9c1382ed0",
   "metadata": {},
   "source": [
    "### Benchmarking using a larger problem\n",
    "\n",
    "Now try a larger problem size. It helps bring more potential out of this GPU version, but not too much. We can still see the GPU version runs faster though.\n",
    "\n",
    "Note: the single block version GPU blelloch scan implementation has a baked-in limitation of only assuming 1024 threads per block, so the largest problem size the multi-block version can handle is $1024*1024 = \\mathbf{2}^{\\mathbf{20}}$ (n_blocks <= 1024). But this is sufficient for demonstrating simple parallelism on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db25a864-db7d-4bc7-9f39-9e0633ede34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctness check:\n",
      "true\n",
      "\n",
      "=== Benchmark ===\n",
      "CPU serial exclusive scan:\n",
      "  730.100 μs (3 allocations: 4.00 MiB)\n",
      "\n",
      "GPU multi-block exclusive scan:\n",
      "  441.700 μs (337 allocations: 9.48 KiB)\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "# Problem size (larger)\n",
    "N = 2^20\n",
    "h = rand(Float32, N)\n",
    "d = CuArray(h)\n",
    "\n",
    "# Warm-up (important: triggers compilation)\n",
    "gpu_scan_multiblock!(d)\n",
    "synchronize()\n",
    "\n",
    "println(\"Correctness check:\")\n",
    "cpu = cpu_serial_scan(h)\n",
    "gpu = collect(d)\n",
    "println(cpu ≈ gpu)\n",
    "\n",
    "println(\"\\n=== Benchmark ===\")\n",
    "\n",
    "println(\"CPU serial exclusive scan:\")\n",
    "@btime cpu_serial_scan($h);\n",
    "\n",
    "println(\"\\nGPU multi-block exclusive scan:\")\n",
    "@btime begin\n",
    "    copyto!($d, $h)           # reset GPU input\n",
    "    gpu_scan_multiblock!($d)\n",
    "    synchronize()             # wait for GPU completion\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc937df-558e-4604-93fa-a975ef5414ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12.2",
   "language": "julia",
   "name": "julia-1.12.2-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
